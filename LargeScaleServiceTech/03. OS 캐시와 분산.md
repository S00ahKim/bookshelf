# OS 캐시와 분산
> OS 캐시로 제대로 처리할 수 없을 때, 분산을 고려한다

### OS 캐시란
> 메모리로 디스크 액세스를 줄일 수 있도록 OS는 캐시 구조를 갖추고 있음
- OS는 관리 이점을 위해 가상 메모리를 사용함
- 가상 메모리에서는 데이터를 적당히 잘라 블록(페이지)으로 다룸 `페이지=가상메모리의 최소단위`
- 리눅스의 페이지 캐시는 한 번 할당한 메모리를 해제하지 않고 남겨두는 것

### I/O 부하 줄이기
1. `데이터 규모 < 물리 메모리` => 모두 캐싱 가능
    * 전부 캐싱할 수 없다면, 복수 서버로 확장
    * CPU 부하분산은 단순히 증설
    * I/O 분산에는 국소성 고려
2. 압축해서 저장하면 캐싱 가능한 비율이 늘어남
3. 때로는 SW를 고치는 것보다 서버 메모리를 좋은 걸로 바꿔 끼는 게 경제적 이득

### 국소성을 살리는 분산
- 단순 서버 증설을 하면 캐시 용량이 부족해지는 부분이 또 발생한다!
    * 조금은 빨라질 수 있지만, 서버를 늘려서 10~100배는 빨라져야 한다.
- 국소성을 고려한 분산? **데이터에 대한 액세스 패턴을 고려해서 분산시키는 것**
    * 처리 방향에 따라 특정 방향으로 치우치는 경우가 있음
- 구체적인 방법
    1. 파티셔닝
        * 테이블 단위 분할에 의한 파티셔닝
            + 특정 테이블들에 같이 액세스되는 경우가 많으면 같은 서버에 위치하게 함 
            + 애플리케이션에서 특정 요청을 특정 서버로 보내도록 변경 필요
        * 테이블 하나를 여러 작은 테이블로 분할
            + 데이터 특성을 기준으로 테이블을 쪼갬
            + 쪼개는 기준이 변경되면 테이블을 병합하고 다시 쪼개야 함
    2. 요청 패턴을 '섬'으로 분할
        * 요청하는 주체가 누구냐에 따라 응답 서버를 분리
            + ex. 봇에 대한 응답은 속도가 좀 떨어져도 무관하게 구성
            + 구글이 검색랭킹 평가 요소에 응답 속도를 추가하여 지양
        * 정해진 테이블만 액세스하는 API는 특정 서버로 분리
- 페이지 캐시를 고려한 운용 규칙
    1. OS 기동 직후에는 캐시가 쌓여 있지 않으므로 서버를 투입하지 않는다.
    2. 성능평가 또는 부하 테스트도 캐시가 최적화된 뒤 실시한다.