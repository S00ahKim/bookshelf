# 구글 드라이브 설계

## 구글 드라이브란?
- 파일 저장 및 동기화 서비스
- 기능
  * 여러 포맷의 파일을 클라우드에 암호화해서 보관 (파일 업로드, 다운로드)
  * 각종 단말에서 이용 (ex. 모바일 웹/앱, 단말 간 동기화)
  * 기타: 공유, 변경 사항에 대한 알림
- 추정: 가입자, DAU, 배분된 무료 저장 공간, 업로드 가능한 파일 크기, 업로드하는 파일의 평균 갯수 등

## 설계
1. 웹서버
  > 사용자 인증 필요 & HTTPS (데이터 보호) 
  - 업로드 API
    * 단순 업로드 (파일 크기 작음)
    * **이어 올리기** (파일 사이즈가 크거나 네트워크 이슈로 업로드 중단이 발생할 가능성이 있을 경우)
      1. 이어 올리기 URL을 받기 위한 최초 요청
      2. 데이터 업로드 & 상태 모니터링
      3. 장애 발생시 발생 시점부터 업로드 재시작
    * 절차
      1. 메타데이터 추가 (-> 업로드 중임을 알림)
      2. 파일 저장 (-> 업로드 끝남을 알림)
  - 다운로드 API
    * 파일이 변경되었다는 알림을 수신
    * 새 메타데이터를 요청
    * 메타데이터가 반환되는 즉시 해당 블록 다운로드 요청을 전송함
  - 파일 갱신 히스토리 제공 API
2. 데이터베이스
  - 메타 데이터(사용자, 로그인, 파일 정보) 저장
3. 저장소 시스템
  - 실제 파일을 저장
  - 스케일 아웃 전략
    * 데이터 샤딩
    * 다중화를 지원하는 아마존 S3와 같은 외부 솔루션
4. 기타 컴포넌트
  - 로드밸런서: 네트워크 트래픽 분산을 위함 & 장애 발생시 우회
  - 메타데이터 데이터베이스: SPOF 회피 (캐시를 둘 수 있음)
  - 아카이빙 저장소: 오랫동안 사용되지 않은 데이터를 저장하기 위함
  - 오프라인 사용자 백업 큐: 클라이언트가 접속 중이 아닐 때 정보를 이 큐에 두어 나중에 동기화
  - 알림: 이벤트 발생을 알리기 위한 producer-consumer 모델
    * 롱 폴링과 웹소켓 방식이 있음
    * 굳이 오랜 양방향 통신을 유지할 필요가 없기에 롱 폴링 방식 채택

## 살펴보기
### 동기화 충돌
- 먼저 처리되는 변경은 성공, 나중에 처리되는 변경은 충돌로 표기
- 충돌 시점에 사용자의 `로컬 사본`과 서버의 `최신 버전`을 `합칠지` `대체할지` 선택

### 블록 저장소 최적화
- 수정이 일어난 블록만 동기화하는 `델타 동기화` 기법
- 블록 단위로 압축

### 높은 일관성
- 캐시의 사본은 항상 원본과 일치해야 한다 (=원본이 변경되면 캐시 무효화)

### 저장소 공간 절약
> 파일의 여러 버전을 여러 데이터센터에 보관할 때, 모든 버전을 자주 백업할 경우 공간 이슈가 생김
- 중복 제거 (해시값을 비교)
- 지능적 백업: 보관해야 하는 파일 버전 개수에 상한을 둠 or 중요한 버전만 보관
- 아카이빙 저장소 활용

### 장애 처리
- 로드밸런서 장애: 부 로드밸런서가 활성화 & 평소에 서로 heartbeat 체크
- 블록 저장소 서버 장애: 다른 서버가 미완료/대기 상태의 작업 이어받음
- 클라우드 저장소 장애: 여러 지역에 다중화했으므로 다른 지역의 파일 가져옴
- API 서버 장애: 해당 서버에 요청을 보내지 않음
- 알림 서비스 장애: 접속 중인 모든 사용자는 알림 서버와 롱 폴링 연결을 하나씩 유지함
  * 한 서버가 백만 개의 연결을 관리 가능
  * 한 서버의 장애는 백만 개의 연결을 새로 만들어야 함을 의미 (시간이 걸릴 수 있음)

## 밑줄
- 기능적 요구사항 외에 다음의 비-기능적 요구사항을 이해하는 것도 중요하다. 안정성, 빠른 동기화 속도, 네트워크 대역폭, 규모 확장성, 높은 가용성 (p. 279; `시스템 특성에 따라 자연히 필요로 하는 특성들`)
- 개략적 설계안의 다이어그램을 제시하고 시작하는 대신, 이번에는 다른 접근법을 취해보겠다. 모든 것을 담은 한 대 서버에서 출발해 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가는 것이다. (p. 280)
- **블록 저장소**는 파일을 여러 개의 블록으로 나눠 저장하며, 각 블록에는 고유한 해시값이 할당된다. 이 해시값은 메타데이터 데이터베이스에 저장된다. (...) 파일을 재구성하려면 블록들을 원래 순서대로 합쳐야 한다. (p. 287)

## 질문